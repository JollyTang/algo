# 美团实习

## 数据集标注系统
1 数据集标注系统。
这个系统大概分这么几个模块，
数据集管理模块，包含了数据的导入，预览，删除，修改。每个数据的设计是三层结构，第一层的dataset，第二层的operator，第三层的hbaseid。通过dataset区分不同的数据集，通过operator区分同一个数据集的不同血缘关系，通过hbaseid区分同一个数据集同一个版本下的不同数据。做到不同数据集，不同数据版本之间的隔离。并且数据集这一块通过血缘重放机制实现任意版本的查询。
标注任务系统模块。包含了标注任务的创建，查询，进入标注状态等功能。针对不同的业务方的需求，从标注任务类型来看，可以分为平铺标注，也就是单条数据的标注，session会话标注，也就是标注的粒度是整个会话。gsb标注，也就是对比标注。从标注的数据来看，可以支持各种标注类型，包括视频，音频，图片等数据类型。从分配方式来看，支持平均分配，按段分配，按比例分配等方式。创建过程中，还可以添加各种校验规则，以及其他提示信息等。这一块也是使用了工厂模式进行处理的，非常易于修改和扩展。
然后就是打标页面，根据不同的任务类型进行不同的渲染，还支持全局搜索和不同数据之间的任意跳转功能等。

2 存储寻址优化与二级索引设计
由于标注任务分成了平铺和对话和gsb三种不同任务类型，那么查询过程针对不同任务类型也稍微有些不同。
假设是平铺类型，用户在他任务的第一条数据上进行标注，首先需要映射成hbaseid，之后通过抽象出的hbaseapi直接就可以获取指定数据。
假设是对话类型的，用户在他任务的第一条数据上进行标注，首先要转换成sessionid，然后在根据第二层映射关系找到这个session中的某个hbaseid。gsb标注也是同样差不多的逻辑。
通过对任务的抽象，顺带封装了各自的寻址逻辑。方便后续扩展和修改。

3 在线工作流 开发工作流组件粒度选择变量功能，提升工作流配置的灵活性和可维护性。
工作流中存在各种变量名称，刚开始是一个平铺的结构，如果一个变量在工作流前后都用到过，后面的变量名称会覆盖掉前面的名称。
为了实现不同组件变量名内容是不一样的功能，于是进行了组件粒度选择变量功能的开发。
在工作流的整个执行过程中，本质上有个graphcontext用于存放整个工作流的各种变量信息。
通过在组件执行流程中向graphcontext中存数据的时候加上组件前缀还进行不同组件之间相同变量名的区分。

4 离线工作流：解决Spark环境导致的数据集隔离问题，优化数据处理性能和资源利用率。
由于我们平台存在三个不同的环境，而spark只有正式环境，如果用户想从测试环境通过工作流来导入数据集，会导入到正式环境中，为了解决这个问题，首先在管理端新增一个导入hbase的接口供spark调用。之后在spark的driver端聚合数据然后发起写入请求解决了环境隔离的问题。
这个当时由于急着上，所以是这么处理的。
现在细细想想其实有更好的处理方法，完全可以把发请求这个阶段放到executore中来做，这样效率应该会快很多。
当然放到executor来做肯定也会有别的问题，比如httpclient的序列化，也会提高管理端的QPS，数据可能倾斜，也要加各种失败重试等操作。

5 任务巡检：开发定时任务巡检评测系统的全功能模块，实现自动化质量监控，设计多维度评测指标体系，支持实时通知。
通过AICoding完成整个模块curd和前端页面(任务查看页，任务创建页，任务详情页面)的开发工作。
实现按周期触发定时任务调度触发评测，最后进行大象通知。



# 腾讯实习