# 自我介绍
面试官你好，我是jollytang，是中国科学技术大学软件学院研二的学生，技术栈主要是java，python，go相关的。之前在腾讯ieg增值服务部实习，做的主要是监控系统相关的工作，包括监控管理端，数据处理引擎，监控告警引擎等服务。现在在美团履约平台技术部实习，主要做工作流，数据集，数据标注，任务巡检评测等工作。平常生活中对AI有些兴趣，所以也做了一个Agent项目进行尝试。日常工作中也在慢慢把AI加入进来，可在AI帮助下进行全栈开发。如果用几个词来描述我之前的工作的话，那就是监控可观测，数据闭环，Agent，AI全栈开发，以上就是一个简单的自我介绍，谢谢。

## os
1. select poll epoll是啥，区别是啥
他们都是函数 用来监听哪些fd数据准备就绪了，select 和 poll都是轮训 select有个最大数量1024的限制，epoll不用轮训 采用事件监听机制 o(1)返回。
2. epoll的事件回调是怎么做的
epoll 在内核里维护一棵红黑树保存所有监听的 fd，并为每个 fd 注册一个**「就绪回调」；当网卡/文件系统检测到该 fd 有新数据时，直接调用这个回调，把 fd 插进一个就绪链表**，epoll_wait 只需返回这条链表即可，全程无轮询。


## 可观测
1 整体架构
Q1：整个监控告警链路端到端的数据流是怎样的？
→ 你先画 30 秒流程图：Kafka → 环形队列 → 双速检测 → Map<规则> → 告警。
追问：环形队列容量 120个 保存2h数据、过期策略，不用过期。
写入失败如何处理？
Kafka 不可用
• 触发条件：Broker 失联、Topic 丢 ISR。
• 兜底：本地磁盘双写——监控告警引擎先把原始数据 append 到本地滚动文件；Kafka 恢复后，用 LogReplayer 线程批量补发，保证 0 丢失。
监控告警引擎进程崩溃
• 触发条件：OOM、panic kill。
• 兜底：环形队列做内存镜像 + 定期刷盘（每 30 s 序列化到本地 RocksDB）；重启后先读 RocksDB 重建窗口，再继续消费 Kafka。
Q：环形队列写入会出现并发冲突吗？
A：不会，我们是单线程写模型。
Kafka 消费线程把数据先放进分片 Slice，再由一个单线程调度器把 Slice 里的数据顺序写入环形队列，全程无锁、无 CAS，CPU 缓存亲和。

2 性能与扩展
Q2：单节点 2 k QPS 的瓶颈在哪儿？
→ CPU / 锁 / GC / 网络？
追问：如果流量翻 10 倍，你会怎么水平扩容？（Kafka 分区、无状态多实例？）
3 一致性 & 可靠性
Q3：Kafka 消息重复或乱序，会不会导致窗口计算错误？
→ 版本号去重、幂等写、exactly-once 语义如何保证？
追问：监控告警引擎重启后如何恢复现场状态？
4 规则引擎
Q4：DSL 里各字段含义、校验逻辑、优先级冲突怎么解决？
→ 现场写一条示例规则，然后问：
如果阈值 200 ms、窗口 5 min，但 5 min 内只有 3 条数据，算还是不算？
5 窗口语义
Q5：10 分钟滑动窗口 vs Flink 的 10 min 翻滚窗口差异？
→ 你们为什么选滑动？
追问：迟到数据（>10 min）怎么处理？直接丢弃还是更新旧桶？

# 美团实习

## 数据集标注系统
1 数据集标注系统。
这个系统大概分这么几个模块，
数据集管理模块，包含了数据的导入，预览，删除，修改。每个数据的设计是三层结构，第一层的dataset，第二层的operator，第三层的hbaseid。通过dataset区分不同的数据集，通过operator区分同一个数据集的不同血缘关系，通过hbaseid区分同一个数据集同一个版本下的不同数据。做到不同数据集，不同数据版本之间的隔离。并且数据集这一块通过血缘重放机制实现任意版本的查询。
数据集导入如果是通过文件导入的话，采用补偿事务，先向mysql创建一条数据，然后把文件上传到s3，之后会向mysql的状态位设置为一个枚举值，就是导入s3成功，然后就是写hbase，写完之后在把mysql中的数据的状态位设置为完成。这样如果导入s3失败，会提醒用户失败，如果导入s3成功，写hbase失败，会有个定时任务扫描数据库中导入s3成功但是没有导入hbase的，然后再次进行导hbase。
标注任务系统模块。包含了标注任务的创建，查询，进入标注状态等功能。针对不同的业务方的需求，从标注任务类型来看，可以分为平铺标注，也就是单条数据的标注，session会话标注，也就是标注的粒度是整个会话。gsb标注，也就是对比标注。从标注的数据来看，可以支持各种标注类型，包括视频，音频，图片等数据类型。从分配方式来看，支持平均分配，按段分配，按比例分配等方式。创建过程中，还可以添加各种校验规则，以及其他提示信息等。这一块也是使用了工厂模式进行处理的，非常易于修改和扩展。
然后就是打标页面，根据不同的任务类型进行不同的渲染，还支持全局搜索和不同数据之间的任意跳转功能等。

2 存储寻址优化与二级索引设计
由于标注任务分成了平铺和对话和gsb三种不同任务类型，那么查询过程针对不同任务类型也稍微有些不同。
假设是平铺类型，用户在他任务的第一条数据上进行标注，首先需要映射成hbaseid，之后通过抽象出的hbaseapi直接就可以获取指定数据。
假设是对话类型的，用户在他任务的第一条数据上进行标注，首先要转换成sessionid，然后在根据第二层映射关系找到这个session中的某个hbaseid。gsb标注也是同样差不多的逻辑。
通过对任务的抽象，顺带封装了各自的寻址逻辑。方便后续扩展和修改。

3 在线工作流 开发工作流组件粒度选择变量功能，提升工作流配置的灵活性和可维护性。
工作流中存在各种变量名称，刚开始是一个平铺的结构，如果一个变量在工作流前后都用到过，后面的变量名称会覆盖掉前面的名称。
为了实现不同组件变量名内容是不一样的功能，于是进行了组件粒度选择变量功能的开发。
在工作流的整个执行过程中，本质上有个graphcontext用于存放整个工作流的各种变量信息。
通过在组件执行流程中向graphcontext中存数据的时候加上组件前缀还进行不同组件之间相同变量名的区分。

4 离线工作流：解决Spark环境导致的数据集隔离问题，优化数据处理性能和资源利用率。
由于我们平台存在三个不同的环境，而spark只有正式环境，如果用户想从测试环境通过工作流来导入数据集，会导入到正式环境中，为了解决这个问题，首先在管理端新增一个导入hbase的接口供spark调用。之后在spark的driver端聚合数据然后发起写入请求解决了环境隔离的问题。
这个当时由于急着上，所以是这么处理的。
现在细细想想其实有更好的处理方法，完全可以把发请求这个阶段放到executore中来做，这样效率应该会快很多。
当然放到executor来做肯定也会有别的问题，比如httpclient的序列化，也会提高管理端的QPS，数据可能倾斜，也要加各种失败重试等操作。

5 任务巡检：开发定时任务巡检评测系统的全功能模块，实现自动化质量监控，设计多维度评测指标体系，支持实时通知。
通过AICoding完成整个模块curd和前端页面(任务查看页，任务创建页，任务详情页面)的开发工作。
实现按周期触发定时任务调度触发评测，最后进行大象通知。



# 腾讯实习

1 监控管理端：负责监控管理端前后端功能开发与维护，包括链路统计、链路详情、节点视图、监控策略配置等核心模块，运用策略模式和责任链模式设计灵活的数据兼容处理机制，实现多数据源统一接入和特殊数据处理。
监控管理端大概有这么几个功能模块，数据接入模块，用户在管理端注册应用，模块，接口等信息，然后通过sdk上传数据就可以直接用了。
数据查询模块。就可以查监控相关各个维度的信息。
从维度是分可以有活动维度，主调维度，被调维度，ip，错误码，时间范围等各个维度。
从指标来看，有请求次数，成功次数，失败，超时等次数信息和各自占比。
除了这些宏观数据之外，还可以看到某一分钟的某链路的详细信息。还有活动排行，某个活动的请求调用拓扑图等，某一分钟的耗时分布，比如P10,P50,P99。
监控配置模块，通过在管理端配置告警条件，管理端会把这个告警配置信息通过kafka传到监控告警引擎，监控告警引擎会修改对应的配置进行检测，如果满足告警条件就会向工单系统发送请求创建工单，同样也会进行企业微信和邮件通知。
最后还有工单模块，会显示告警产生的各种工单，可以看到告警的原因等信息。

2 数据统计服务：基于不同业务需求设计分片表统计方案，实现大规模数据的高效统计处理。
在数据上报过程中，会首先经过这个服务进行分表，可以看到上面的查询条件的维度是非常多样的，为了支持多维度查询，数据统计服务会把原始数据进行加工处理过滤分表，根据业务需求分到不同的表中。实现上层应用的高速查询。

3 监控告警服务：在现有告警策略基础上，新增数据断崖式下降告警和平均值告警等智能告警功能，实现告警抑制、告警聚合等高级功能
原有监控仅支持按聚合后的请求数进行告警，业务方那边需要有掉0告警，和按平均值告警的功能。
掉0告警是通过填充0数据实现的，对原来业务逻辑无任何影响，但是在没有数据上报的时候监控依旧可以查看到0数据，复用原来的检测逻辑就可以实现，对代码修改是最少的，也是最安全的。
按平均值告警是通过记录上报的ip的数据，然后总数/上报ip数计算得出的。先在管理端新增配置项，让用户可以按平均值告警进行配置，然后在监控引擎告警之前新增对告警配置的判断修改总数计算逻辑来实现的。同样也是对代码修改最少，安全性最高的修改。

4 工单AI分析：负责工单相关知识库的构建，包括各种链路信息及错误码信息等，搭建工单分析链路，可对工单及产生工单的日志进行分析。
梳理工单相关的错误码信息和告警类型，编写提示词，创建工单的时候会异步像AI分析服务发请求，然后服务会提取日志信息，过滤无效信息，形成分析结果异步入库。用户可以在工单模块查看工单详情的时候看到这个分析。

5 大规模数据处理与统计：设计基于MapReduce思想的数据处理方案，处理140万+行Excel礼包发放数据，开发数据分片处理框架实现并行计算，解决并发处理的数据一致性问题，完成近两年礼包发放数据峰值统计。
当时leader让分析统计近两年礼包发放峰值，给了我一个包含140万行数据的excel，里面是礼包id和业务方id。首先看了下管理端目前没有接口能实现这个需求，所以新增了一个接口来进行信息的查询。然后就开始读取数据发个请求获取结果然后写到文件里，跑着跑着发现程序经常挂掉，想一次性跑完140万数据不太现实，于是参考maprduce思想，先对数据进行切分，切分成15个小文件，每个文件最多10万数据，这样失败重试也会更容易，成本不会特别高，而且可以并发的跑提升效率。但是实际跑的过程中又发现问题，一是并发上去了服务器的内存马上就到上限，然后服务重启，导致处理流程不连续。看了下服务器的内存使用情况，请求非常低的时段内存占用就百分之四十，登上机器看了下，通过内存分析工具定位到是有缓存了九个多g的缓存数据，和正式员工确认这个可以不用缓存之后把相关的代码注释掉，在部署之后内存占用直接到百分之三，机器的问题就解决了。然后我客户端这边，发现开启并发后写文件会有并发问题。于是写了个程序过滤掉错误数据，并生产未处理的数据，方便后续二次处理。又写了个聚合排序的脚本，等之后全跑完使用。然后开了两个机器，四个服务，跑了两天跑完了。
现在看来还是有很多优化点的，比如之前是采用网络传输的方式，这种方式效率是最低的，应该是可以改成在程序内读文件调方法写文件解决的，不过就要麻烦负责部署业务的部门帮忙捞下数据。或者采用spark框架来做，效率应该会比之前的方法高很多。